{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0de9b99",
   "metadata": {},
   "source": [
    "## Le deuxième objectif du projet consiste à expliciter et à implémenter 2 approches de transfer learning : \n",
    "**A : l’utilisation des features d’un DL avant la couche dense comme représentation des images puis apprentissage d’un modèle de ML “classique”** \\\n",
    "**B : fine-tuning d'un modèle existant à de nouvelles données**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4092ce89",
   "metadata": {},
   "source": [
    "# Transfer learning de type A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66e5e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c44e7",
   "metadata": {},
   "source": [
    "## Avec Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bad1d90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pierre/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/pierre/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/pierre/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc1c66f1e984f0389508864bf57bb80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TRANSFER LEARNING\n",
    "#The authors did that : using feature extraction from ImageNet VGG16 - library : keras\n",
    "#We do : using feature extraction from ImageNet RESNet50 - library : pytorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "conv_base = models.resnet50(pretrained=True)\n",
    "layers = list(conv_base.children())[:-2] #on retire les couches denses #on a un poids de 2048 \n",
    "conv_base = nn.Sequential(*layers) \n",
    "conv_base.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e002dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 1: Fast feature extraction without data augmentation\n",
    "#Run the conv_base on the dataset and save as Numpy array on disk\n",
    "#Then build the dense layer on this\n",
    "#This is faster to run, but we cannot augment the data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "train_dir = \"./train_another\"\n",
    "validation_dir = \"./validation_another\"\n",
    "test_dir = \"./test\"\n",
    "#transform\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(150,150),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transform)\n",
    "validation_dataset = datasets.ImageFolder(validation_dir, transform=data_transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=20, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc696ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define extract_features\n",
    "#generators yield data indefinitely\n",
    "#have to break after we have seen every image once\n",
    "#try parallized (cuda)\n",
    "\n",
    "import torch.cuda\n",
    "\n",
    "\n",
    "def extract_features(directory, sample_count, batch_size):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    #on impute les poids de Resnet\n",
    "    \n",
    "    features = torch.zeros(size=(sample_count,2048,5,5), dtype=torch.float32).to(device)\n",
    "    labels = torch.zeros(size=(sample_count,), dtype=torch.long).to(device)\n",
    "\n",
    "\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Resize((150,150)), #dimension de la cible\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    image_dataset = datasets.ImageFolder(root=directory, transform=data_transform)\n",
    "    data_loader = torch.utils.data.DataLoader(image_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in data_loader:\n",
    "        inputs_batch, labels_batch = inputs_batch.to(device), labels_batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            features_batch = conv_base(inputs_batch)\n",
    "        features[i * batch_size: (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "017f0875",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = extract_features(train_dir, 10000, 20)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 2000, 20) #batchs(20) à remettre en pyTorch\n",
    "test_features, test_labels = extract_features(test_dir, 2000, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd353a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Etape de flatten\n",
    "train_features = train_features.reshape(10000, 2048*5*5)\n",
    "validation_features = validation_features.reshape(2000, 2048*5*5)\n",
    "test_features = test_features.reshape(2000, 2048*5*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70853161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30], Loss: 0.4075\n",
      "Epoch [20/30], Loss: 0.3325\n",
      "Epoch [30/30], Loss: 0.2965\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABIGklEQVR4nO3dd5xU1fn48c+zvc2yjd4WkCKooCBEQcUYo8Yo1giJiS226NeY/JJvjGmaxMREv2lfjQYTYhc1iu2riBXsUgTpSFlgKcuyvZeZ5/fHubvMLltml52tz/v1mtfM3HvuvedOe+acc+9zRVUxxhhj2iqiqytgjDGmZ7IAYowxpl0sgBhjjGkXCyDGGGPaxQKIMcaYdrEAYowxpl36ZAARkddE5IqOLtuVRCRLRL4ShvW+KyLf9R5/S0SWhFK2HdsZISKlIhLZ3rqa0IjI7SLyzxbmXyki73dmncKttX0+wnU3+90TkXgReVlEikTk2XBsvytFdXUFQiUipUFPE4AqwO89v15Vnwh1Xap6TjjKdkci8lPgHFU9tdH0DGAvcIKqrgtlXd5rHPLr3Eq9soDvquqb3rp3AUkdse5mtifANqBSVSeGazs9gar+ru6xiGQCO4BoVa3tskq1QETeBR5X1XYHgOB97mSXAAOB9CN9fUXkDuAoVb28IyrWEXpMC0RVk+puwC7gvKBp9T9qItJjgmIneQw4WURGNZo+F1gbavDoBU4FBgCjReTEztywfSYPCcdr0c1f35HAlu4QnMPyOqlqj7sBWcBXvMezgWzgJ8B+3A9mKvAKkAsUeI+HBS3/Lu7fL8CVwPvAvV7ZHbh/7O0pOwpYBpQAbwL34/45NbUPodTxN8AH3vqWABlB878N7ATygJ8FvyZNbGsJ8MtG0z4FbmnPaxU070xgE1AE3AcsDSo7Bnjbq99BXMslxZv3GBAAKoBS4L+BTECBKK/MEOAlIB/YClwbtN07gGeAR73XZj0wrZXPzAKvDs8D9zWaNwl4w9tWDnC7Nz0SuB3XcikBVgLDG9e1mdfpA+DP3jp/29Lr4S0z3KtbrlfmPiDWW/7YoHIDvNetfxP7uBOY6j2+3KvjRO/5d4EXgl6/x73Hu7xypd7tJFr5nDfzffwpsMEr/28groXvZwRwm/e65nnvZVoz674L19NQ6dXvPm+6AjcBXwA7vGl/BXYDxd57dUqjz0zdPte9f1d4+38Q+FlQ2RbrR4jfPeBOoBqo8ep+jTf9amCj91q9DowMWqbJfQDObrSuNY1/C1vYz2u8/VzW0vYBwX1mD+C+058Dx7T0veoxLZBWDALScNH+OtwH4N/e8xG4L9x9LSw/A9gMZAB/BP7ldXm0teyTuB/mdNwb+e0WthlKHb8JXIX70YgBfgQgIhOBB7z1D/G2N6yFbT0SXBcRGQ9MAZ4KsR6H8brAngN+jnsttgEzg4sAv/fqdzTuB/IOAFX9Ng1bkX9sYhNP4X54huC6AX4nImcEzT8fWAik4AJNs3UWkQRvHXVdcHNFJMab58MF+8Xeto4C3vIW/SEwD/gakIz74pW39LoEmQFsx713d9HC6+GN+7yC+1HKBIYCC1W1ytvH4C6LecCbqprbxDaX4n6wwbW4tgOnBT1f2sQydV2bKd578VFQ/UP9TgB8CzgLFyjH4T4XdRp/P28BLvDqNgT3Q3Z/UytV1Z8B7wE3e/W7OWj2BV4967okl+M+12m47+KzIhLXQp1nAeOBM4BfisjR3vRm69eW756q/gr4HfC0V/d/icgFuD8lFwH9vX17KmixJvdBVRc3WtfkFvarsdNwn7mzWtn+V3Gfh3G479VluCDZvJaiS3e9cXgLpBrvH08z5acABUHP36Xhv8WtQfMScFF7UFvK4n58a4GEoPmP00wLJMQ6/jzo+feAxd7jX+J+YOrmJXqvQXMtkATcP5qT9dC/uhfb+Vq97z3+DvBxUDnB/eB/t5n1XgB81tR7qA3/LUXhflz9gC9o/u+Bh/XQv6w3g+ZNBCpaeG0vx/2zj8L9qy8ELvTmzQuuV6PlNgNzmpheX9cWXqddrbzf9a8H7l9/bvD6gsrNwP0jjfCerwC+0cw6rwFe8h5vxLU6FnrPd+LGu+pev8b/UoP35Upa+E408328Iej514BtzX0/vbqdEfR8MO6f9WH73/i1DZqmwJdbeY0LgMkt7HNwS/tTYG5r9aPt37367XrPX8NriXjPI3B/Ska2ZR9a+B41tZ+jQ9k+8GVgC/Clus9ba7fe0gLJVdXKuicikiAi/xCRnSJSjOtWSmnhCJ/9dQ9Ute4fZnMDus2VHQLkB00D98VvUoh13B/0uDyoTkOC162qZbTwT8Gr07PAd7x/kd/CtUra81rVaVwHDX4uIgNEZKGI7PHW+zju32wo6l7LkqBpO3H/zOs0fm3iWujjvQJ4RlVr1f2rf96bBi5YbWtmuZbmtabBe9/K6zEc2KlN9JOr6idAGXCaiEzAtZBeamabS4FTRGQQrvvtaWCmN1DeD1jdhvq35TsBDfd3J+49rNPg+4n7sVokIoUiUoj7wfYDA0XkQe9ovFIRub2VOjZ+jf+fiGz0jngqxO1zS5+55r5fzdaPNn73mjAS+GvQuvNxf76GtnMfQhH8OjW7fVV9G9eSvx/IEZH5IpLc0op7SwDRRs//H65pOkNVkznUTG+pCX6k9gFpXndJneEtlD+SOu4LXre3zfRWlnkE+AZu3MKH6zI5kno0roPQcH9/j3tfjvPWe3mjdTZ+z4Ltxb2WvqBpI4A9rdTpMCIyDPfP6nIR2S8i+3HdWV/zuuF247pdmtLcvDLvPvi9HtSoTOP9a+n12A2MaCEAPuKV/zbwn0Y/xoc2qLoV90N4C66/uwT3I3kdruUYaGqxZrbZVsHv/Qjce9jcNnbjxlRSgm5xqrpHVW/QQwfH/K6Z5Q9br4icghtn+QaQqqopuH789nznm60f7fvuNV739Y3WHa+qH4awD029DmW0/DlsvFyz2wdQ1b+p6lTcuOA44Mct7UxvCSCN+XB9+YUikgb8KtwbVNWduO6FO0QkRkROAs4LUx3/A3xdRGZ5ffm/pvX38j1c1818XBO8+gjr8X/AJBG5yPvhu4WGH14fbrCvUESGcvgHMQcY3dSKVXU38CHwexGJE5HjcN0z7TmE+Nu4ZnnduM8U3BcjG9d99QowSERuFZFYEfGJyAxv2X8CvxGRseIcJyLp6sYf9uCCUqSIXE3zQahOS6/Hp7gfprtFJNHb5+DxpMeAC3FB5NFWtrMUuJlD4x3vNnreWC7ugIYm34s2uElEhnmfodtxrZ/mPAjcJSIjAUSkv4jMaaF8s5+VID5cF3IuECUiv8SNW7VHS/Vrz3ev8bp/KiKTvHX3E5FLQ9yHHCBTRIK3txo3phctItNwf47atX0ROVFEZohINC4wVXLoVIkm9dYA8hcgHnd0xce4AdLO8C1cf3Ye7sibp3HnqzTlL7Szjqq6HncEypO4H54C3A9iS8so7sdnJA1/hNpVD1U9CFwK3I3b37G4I4/q3AmcgPsH9X+4bqNgvwd+7jWlf9TEJubh+nD3AouAX6nqG6HUrZErgL+r6v7gG+6LdIX3L/1MXLDfjzuq53Rv2T/hjsBZghtD+hfutQK4FhcE8nD/1j5spR7Nvh6q6ve2fxTu4IJs3ABm3fxsYBXun+R7rWxnKe6HaFkzzxvwuqfuAj7w3osvtbL+5jyJe522e7fftlD2r7huuCUiUoL73M1opfwlIlIgIn9rpszruP79LbgutEpa6EJuRbP1a893L5iqLgL+ACz0ujLXAXXnmrW2D3UnIuaJyCrv8S9wf14KcJ+xJ49g+8nAQ9666o4yu7el9Yk3kGLCQESeBjapOxrDmHYTkQXAXlX9eauFO5k0OinU9B3d+QScHkfcCWr5uOPmvwrMwf1DN6bdvEHwi4Dju7gqxjTQW7uwusogXJ9zKfA34EZV/axLa2R6NBH5Da6b4R5V3dHV9TEmmHVhGWOMaZewtkBE5GwR2SwiW0Xktibmp4rIIhH5XEQ+FZFjQl3WGGNM1wpbC0TciWhbcEe4ZONO0Z+nqhuCytwDlKrqneJOkrpfVc8IZdmmZGRkaGZmZlj2xxhjeqOVK1ceVNX+7Vk2nIPo03HpELYDiMhC3KBycBCYiDucE1XdJCKZIjIQd8x3a8seJjMzkxUrVnT4jhhjTG8lIjvbu2w4u7CG0vAY5mwapqIAWIM7ugQRmY47R2FYiMviLXediKwQkRW5uU3llzPGGBMO4QwgTaUQaNxfdjeQKiKrgf8CPsOdiRnKsm6i6nxVnaaq0/r3b1crzBhjTDuEswsrm4b5cYbRMD8OqlqMS1del0tph3dLaG1ZY4wxXSucLZDlwFgRGeXljJlLoyyiIpLizQOXenqZF1RaXdYYY0zXClsLRFVrReRmXH6XSGCBqq4XkRu8+Q/iLnLyqIj4cQPk17S0bLjqaowxpu161YmE06ZNUzsKyxhjQiciK1V1WnuWtVQmxhhj2sWSKRpjTDdRUllD1sFytueWULlrFVX9RpOels6A5FgG+GIZ4IsjPqa1i4V2HgsgxhjTiSpr/OzKL2d7bhk7DpaRddDdbz9YRl5pBWdHLOe/ol5gYsROCjSJf9Wew23+syjxLjzoi42if3IsA31x9YFlSEo8V80c1en7YgHEGGPaqNYfYMO+YlZkFbByZwFrsgspr/ajqigQCLh71J3AFlBFFRSlqjZA8NBzRlIsY9Jj+eGgNZyd/wRp5duoShlD9fQ/kLjtbX607VluTVjM5sxv8VH/b5BdGceBkkoOFFfx2a5CcoorSUuMsQBijDHhoKp8nl3Eq+v28e6mXOJjIhmRllB/G56WwIj0BAYlxxEZcfh5zMWVNaza6YLFiqwCVu8upKLGXe11aEo8x49IISUhGkGIEHCntYEIRIgg3mMRISEmklEZiYzKSCQzLZbkL16EZfdCzhfQfwKc8y9iJ10IEZFw8g2wbw1Ry+5h0sYHmbTzCZh+LZxxMySm1+9beXWLV54NGzsKyxjTLfkDyhcHSkiJj2Fgcmz9j3KoAgHls92FvLZ2H6+t28+ewgqiIoQZo9MA2JVfzt7CSvyBQ7+B0ZHCsFQvoKTFowordxawOacEVYgQmDgkmWkj05iVUcY0/2pS9r0Puz6GhHQYcLR3m+juUzIhooljlfw1sGYhvPc/ULADBh4Lp/0YJpzXdHmAnPUu0KxfBNHxcOI1cPItkDSgTa9LY0dyFJYFEGNMt3GguJJlXxxk6ZZc3v8il4LyGgB8cVGMH+hj3CCfux/oY/wgH2mJMQ2WDwSUlbsK+L/P97F43X72F1cSHSmcMrY/5xwziK9OHES/hOj68jX+APsKK9mVX87ugnJ25bvbbu++1q8cPyKFqSNTmTE4iin+z4nftQy2vwP5291KkodC5iyoLIYDG6AwKDdhdAL0H38ooAw4Ggp3wXt/hqJdMHgKnPYTGH+Oa6KEInezCyTr/gORMTD1Kpj5fUge3K7X3AKIxwKIMT1LdW2AFTvzWbbFBY2N+4oBNy5w6rgMZo7JoLy6ls05JWzZX8qm/cUUV9bWL5+RFMv4QUmMG+ij1q+8vn4/B0qqiImK4MyjfMw5KoKZA/0kVh+Ekhwo3Q+lua57KNYHMYkQkwSxSe4+JslNi02CGB9alotsf9cFjD0rQQOuTOYpMOZ0GH06ZIxt+ONfVep+5A9sgAMbD92X7j9UZug0FzjGnhl64Ggsb5trwaxZCHHJ8MONrmXSRhZAPBZAjAnN1gOlpCXGHPYPvr1q/AE27iumtKq2iYFj109fN4isCnsKK1i2JZePtuVRVu0nKkKYlpnKaeMGcNqYZCZEZBOx/3PXbVNbUb8dVaio8VNUUeNu5TX1j+OoYlxiGUMii0mqOYhUFR9e0YgoSOwPAT9Ul0FNWes7JxEwdKoLFmNOh2EnQmR068s1Vp7vAklEJAyf0f7A0Vj+Dti3BiZd0K7FjySA2CC6MX1EIKC8tekA/1i6jRU7CwCYMMjHSWPSOXlMBtNHpdEvPrQfRn9AWb+3iI+25bFi2z4GZL3M+bwLGsEezWAPGWRrf/ZoBru1P/s1jdpGPzfD0+K5dEoG5/TPZ3JUFnG5r8HmNbBsAwRc15VrHfjqlxFcptUEoL7DJgY0BoiMQXyDIOkY8A2CpIHgGwy+gZA0yE2LT2s4xhDwQ025azVUe7eqUhdcqktdF9TIkyE+pe0veGMJaZA588jX01jaKHfrAtYCMaaXq6r18+Jne/nHsm1syy1jaEo8V83MpLLGz0fb81iRVUBVbYAIgUlD+nHSmHROGpPOiZlpJMW6H/1AQNm0v4SPtufx0bY8PtmRR0xlHpdHvsmVMW+SqkWU+MagcSnElu0hpjwHCboCg0oENQkDqU4aRk3SUKKjY0jMX4fkbgb1jiCKT3VjAoMnH7qljmp+UNl0COvC8lgAMeaQ4soanvxkFwve38GBkiomDk7m+tNGc+6YGKLWP+f+VQ87karkkXy227UmPtqex+pdhVT7A0RGCMcN60f/pFiWZ+XXD2jPTs3lprglnFD0BpGBahh7Fpz0PRh12qFumdpqKM6Gwt1u0LjIu6977q+Gwcc1DBb9hndct44JmQUQjwUQ09tUVPvZlltKdGQEqYnRpCbEEB3Z8j/ynOJKFry/gyc+2UVpVS2zjsrg+tNGMyujHPn477DqUddtUych3fXrD5sGw6ZT0X8yK/fX8tH2g3y0LY+8smqmj0zhgqSNTNv/FLG7lkFUPEz5JnzpRjeIbHosGwMxpodTVfYWVbJxbzGb9hezcX8JG/cVk3WwjECj/3i+uCjSEmNITYghPTGGVG8wPDUhhu25pbyweg/+gHLucUO4/tTRHBOVDR/8DNb+x/3DP+4yOOlmt7LsT2H3csheDlsWAxAvEcwaMJFZw6bBSdPdIPYn/4ANW9yYwhm/gqlXuj5906dZC8SYI6SqbD1QypbV75O68UlKIpLISjqefcmTiYj1ERcdQWxUJHHREcRFR9Y/r6jxs2mfCxab9jU8PHV4WjwTBiVz9KAkpvhKqIn2caA2noKyavLLqikoP3RfUFZDflk1FTV+4qIjuGzacL57ymiGl6yB9/8MX7wO0YnuR/+k70G/YU3vSEWBO1S1LqBkr4CqIjdvyPHwpZvckT7tOQLJdFvWheWxAGI6Q92A8ic78vhkWx5kLeWbNYs4NXItFcQSQw2RBKglgg06mo8DE/jYP4EVgfEUk9hgXQkxkUwY5GPC4GQmDkpkSnwuY2q3En9wvTs0c//nUHc4akI6pI2B9KMgPeg+bTTEJFJR7UcIELf9DfjgL7D7E7fMjBvgxO+2vcUQCEDeF1BT4cYobHyiV7IA4rEAYsKhssbPlpwSPt2Rz8fb81melU9JRRVnRSzn+7GvMEG3URGbQeXU60k55TokIsr9eO/8EHZ+4P7V+6tRBP+AY6gcehIlg2Yg/YYxoPwLd77DvjWwf+2hsYmoeBh0jPvhHngMVJVA/jZ38ljeVijZ17CSyUNdMCnJgYObIWWES3Mx5VsQk9D5L5rpMbptABGRs4G/4i5L+09VvbvR/H7A48AI3HjMvar6b29eFlAC+IHaUHbQAohpD1Ult6TqUCqLvIoG6Sz2F1fWlx2XFsX1Kcv5atEz+Mp2uhbBzFvguLkQHdf0BmoqXJdQ1gcuoGQvh9pD6yQmCQYFHZE0ZAqkj4XIFoYoq0pdKo28rQ0DCwLTr4NJF7a8vDGebhlARCQS2AKcCWQDy4F5qrohqMztQD9V/YmI9Ac2A4NUtdoLINNU9WCo27QAYkJRVetn6frdlL33d8qLC9hVGUtubSIF+CjUJApIItaXQUpqf4alJzEiLYFxKQFmFb6Eb/VDUJrjxgRm3gpHn+fOLG6L2irYs8q1IgYd64KQnetgukh3PQprOrBVVbcDiMhCYA6wIaiMAj5xaTaTgHygtvGKjDlSqsrq3YU8v2oPn69Zzu/9f2ZixE4CRBAREYDGGT2qgRyB4hTYnwZluW4sYvTpcNFDMOrU9o8JRMXCyJOOcI+M6XrhDCBDgd1Bz7OBGY3K3Ae8BOwFfMBlqhrw5imwREQU+Ieqzm9qIyJyHXAdwIgRIzqu9qZX2FNYwQuf7eG5Vdlszy3jsuj3eCbq30TExeO/aCGR485yRxqV50NFIVTke4/r7gvc4+h4OPFa171kjAHCG0Ca+nvWuL/sLGA18GVgDPCGiLynqsXATFXdKyIDvOmbVHXZYSt0gWU+uC6sjtwB033UdbWGck2I0qpaXlu7j+dX7eGj7XkAnDoyjgVjniJzz8swYhZc/BAkD3ELxKe6mzGmTcIZQLKB4UHPh+FaGsGuAu5W9+uwVUR2ABOAT1V1L4CqHhCRRbguscMCiOndAgHl6RW7uff1zeSVVRMhEBURQUSEu4+MEKIihMig28HSKiprAmSmJ/DDM8fxjaH5DFpyIxzYAbN/Cqf+uO3jFsaYw4QzgCwHxorIKGAPMBf4ZqMyu4AzgPdEZCAwHtguIolAhKqWeI+/Cvw6jHU13dCa3YX88sV1rMkuYnpmGt8+KZ1AQKkNKP6g+0OPA9QGlOS4aM6bPIQThvdDPp0Pz/7CnQ9xxcvuwj/GmA4RtgCiqrUicjPwOu4w3gWqul5EbvDmPwj8BnhYRNbiurx+oqoHRWQ0sMjrrogCnlTVxeGqq+le8suquef1TSxcvpuMpFj+ctkU5kwZ0rZLmpbnw9OXw+b/c8n+Lnig/hrSxpiOYScSmm7DH1AWLt/FPa9vpqSylqtOzuT7XxmLr/ogLLreDWjXX+ch+HoP3uOkgRAVAzs/gue+6w63PfPXLuGfnUVtTJO662G8xoTss10F/PLF9azdU8SMUWn8es4xjB/kg6I98Mh5LhiMPBlK9ruztsty3eVFG4tPg8pCSBkJ1yyBoSd0+r4Y01dYADFdKr+smj8udt1VA3yx/HXuFM6f7HVXFe5ywaM8H769CIZPP7SgvxbKD7qAUprT8D42CU75kbtOtDEmbCyAmE6jqhwoqWJLTgmb95ewJaeE19fnUFZVy7WnjOKWM8bii/MyvRZkwcPnuXM0vv0CDJvacGWRUa7ryjeos3fDGOOxAGLCorC8uj5IbM4pYcv+UjbnlFBUUVNfJiMplumj0vjxWeMZN/DQda/J2waPnO+uSf2dl+zkPWO6KQsg5ohU1vjZeqCUTftL2Ly/2Lsv4UBJVX0ZX1wU4wf6OPe4wYwf6GPcQB/jBiaRnhR7+AoPboVHvu7yRV35issVZYzpliyAmJCoKtkFFWzcV8zm/SVsynEXQcrKK8fvXTIvJiqCcQOTOGVsfyYM8jFukAsUg5LjQjsEN3ezG/MI+F3wGDgpzHtljDkSFkBMiyqq/byweg+PfJjFpv0l9dNHpCUwfpCPc48dzPhByYwf5CMzPYGoyAioLHYJA6OaaGE0J2cDPHo+IHDl/8GACR2/M8aYDmUBxDRpd345j3+8k4XLd1NUUcOEQT7uOG8ik4enMG6gj8TYJj46/lp478/w7t0gETDsRHfo7ciZ7nFzFzbavxYenQMR0e5s8f7jwrtzxpgOYQHE1FNVPtyWx8MfZvHWxhxEhLMmDeSKkzKZPiqt5W6onA3w4vdg72dw9PnQbzjsfB+W3QP6Bxcchk6FzJkuoAyf4Q633bsaHrsAohNc8Egf01m7a4w5QhZAeilVbX3cIeCHjx+gKnEw/ymbzCOf7GFLTilpiTHcOHsM35oxkiEp8S2vw18D7/8Flv4B4vrBpQ+7q+HVqSyCXR9D1vvuanzv/wXe+x+QSHd0Vd5WiE12wSNt1JHttDGmU1kA6UUqa/y8tm4fT36yixU7C4iNiiA+OpL46EjiYiLrH8fHRJIU6eeGg79jcul7xAJf0RQk4Rx8X7+WM2dMIS46hGy1+9fBCzfC/s/hmIvhnD9CYkbDMnH9YNxZ7gbu2t67P3XBJOsD6D/BXaApdWSHvx7GmPCyXFi9wNYDpTz16S6eW5VNYXkNI9MTOHuSO8GuosZPRbWfiho/lTXuXiqL+Enhrzm2dh1/ibyK2IFj+aYsIXnPUiQiEiZ8HaZf67qammrF1FbD+39y3VPxqXDun2Di+Z2818aYjmC5sPqgqlo/i9ft58lPdvHJjnyiIoSzJg3imzNGcNLodCIimum+Kt4Hj18MgS1w8b+49dhLvBk3Qf52WP4v+Oxx2PAC9D8aTrwGJs+FWO9Ev31r4IWbIGctHHupa3UkpHXGLhtjuhlrgfQUVaXw8NcoSxjOI4lX8s/1Lo/U8LR45k0fwaVTh9Pf18phswe3wuMXQlkezH0cxny56XLV5bD+efj0Idi3GmJ8XhBJgg//111b4+t/hgnndvhuGmM6l7VA+oCcV3/HwH1rEN3ENSzmqJSLSLzwNk6aOLr51kawPSvhiUvd4ytfaTlLbUwCHH85TPmWW+7Th2DVI+Cvhsnz4KzfWavDGGMtkO5ux8EyHnn5LW7PupIlEbPInX4bc0sfJX79Qjf+cPrtMPUql1ywOdvehoWXuwsqXb4IMo5qe0XKDroU6gOObv/OGGO6nSNpgUR0dGWCicjZIrJZRLaKyG1NzO8nIi+LyBoRWS8iV4W6bG93oKSSn7+wljP/tJTTs/6ERsVx+s0PcNU5JxN/6YNw/TKX6uPVH8EDJ8OWJdDUn4G1/4EnvuEOkb3mjfYFD3BHV1nwMMYECVsAEZFI4H7gHGAiME9EJjYqdhOwQVUnA7OB/xGRmBCX7ZVKKmv40xtbmH3Puyz8dDe/Gr+b0+QzYs+4ncT0oYcKDj7OnTsx9ykI1MKTl8JjF0LO+kNlPn4AnrvGnbR31auW+twY06HCOQYyHdiqqtsBRGQhMAfYEFRGAZ+4M96SgHygFpgRwrK9SnVtgCc/2cn/vr2VvLJqzj1uMD/+8kgyn/4pZIyHGdcfvpAITPgaHPUVWPEvl0LkwVlwwnfcUVMf/i8cfR5c9E+Ijuv8nTLG9GrhDCBDgd1Bz7NxgSHYfcBLwF7AB1ymqgERCWVZAETkOuA6gBEjRnRMzTtRIKC8/Ple/mfJFnbll3PS6HRuO2cCk4enuPMsCrLcBZUio5tfSVSMu+73cZe5M8KX/9O1SqZe6c7RiAjhpEBjjGmjcAaQpg4NatxJfxawGvgyMAZ4Q0TeC3FZN1F1PjAf3CB6eyvbFSpr/Pzg6dW8tm4/Rw9O5pGrp3Pq2AyXgqQoG977k2tBjDk9tBUmpME5f4ATr4WcdTBxTtMnAhpjTAcIZwDJBoYHPR+Ga2kEuwq4W92hYFtFZAcwIcRle7Si8hqufXQFy3fm87OvHc01s0Y1PBx3yc9BA/DVu9q+8oyj2j9YbowxIQrnUVjLgbEiMkpEYoC5uO6qYLuAMwBEZCAwHtge4rI91p7CCi558ENW7y7kf+cdz7WnNjqXY/tSWL8IZv3QckQZY7qtsLVAVLVWRG4GXgcigQWqul5EbvDmPwj8BnhYRNbiuq1+oqoHAZpaNlx17Uyb9hdz5YLllFXX8sjV0zlpTHrDAv4aeO0nkDICZt7SNZU0xpgQhPVMdFV9FXi10bQHgx7vBb4a6rI93Ufb8rjusRUkxkTx7A0nMWFQ8uGFlv8TcjfCZU9AdCup1I0xpgtZKpNO8srne/nh02sYmZ7AI1dPb/o6G6UH4J3fuRxVlmfKGNPNWQDpBAve38Fv/m8DJ45M46HvTKNfQjOH5L55J9RUuAy3dvSUMaabswASLqoEAsofXt/MP5Zt5+xJg/jL3BYu1JS9AlY/DiffAhljO7euxhjTDhZAwiTw95MoLMgns3Iif5hwOpdc+CUimwsegYDLaZU0CE77786tqDHGtJMFkHCoqSQidyPFgYFcFLuc2Kx34N5fuWuAjz7dnRg4fAZEedfv+Owx2PsZXDj/0IWbjDGmm7MAEga1ZXlEAesyryDzip/A3lWw7R3Y/g58+Dd3OdjoBBh5MoyeDe//GYZ/CY77RldX3RhjQmYBJAxKC3JJAZJS+rvrdAyf7m6zfwKVxbDzA3eNjm3vuDPOJQK+ZgPnxpiexQJIGJQWugAS7Us/fGZcMow/x93A5byqLHLX9jDGmB7EAkgYVJUcBCA2OaP1wv2GuZsxxvQwYb0iYV9VVewCSGK//l1cE2OMCR8LIGFQW5oPQFLKgC6uiTHGhI8FkDDQinyqNJp+/ZrIdWWMMb2EBZBwqCigkER8cS1cRdAYY3o4CyBhEFVVQIkkuysLGmNML2UBJAyiq4soi7Qzyo0xvZsFkDCIqymiMqpfV1fDGGPCygJIGCT4i6mOtgBijOndwhpARORsEdksIltF5LYm5v9YRFZ7t3Ui4heRNG9elois9eatCGc9O5QqPi2hNjalq2tijDFhFbYz0UUkErgfOBPIBpaLyEuquqGujKreA9zjlT8P+IGq5get5vS6a6T3GDUVxFKDxqd2dU2MMSaswtkCmQ5sVdXtqloNLATmtFB+HvBUGOvTKSpLct2DhLSurYgxxoRZOAPIUGB30PNsb9phRCQBOBt4LmiyAktEZKWIXNfcRkTkOhFZISIrcnNzO6DaR6as0DWYohItgBhjerdwBpCmToLQZsqeB3zQqPtqpqqeAJwD3CQipza1oKrOV9Vpqjqtf/+uzz1VVngAgBhfCIkUjTGmBwtnAMkGhgc9HwbsbabsXBp1X6nqXu/+ALAI1yXW7VUUuRZInAUQY0wvF84AshwYKyKjRCQGFyRealxIRPoBpwEvBk1LFBFf3WPgq8C6MNa1w9SWugCSkNL1rSFjjAmnsB2Fpaq1InIz8DoQCSxQ1fUicoM3/0Gv6IXAElUtC1p8ILDISwUSBTypqovDVdeOVFtaAIAvzQKIMaZ3C+sFpVT1VeDVRtMebPT8YeDhRtO2A5PDWbdw0fI8yjWWFJ9l4jXG9G52JnoHk8pCikgkPiayq6tijDFhZQGkg0VVFVASYa0PY0zvZwGkg8XUFFEeaQHEGNP7WQDpYPE1xVRGWQAxxvR+rQYQEfm6iFigCVFCoJiamJSuroYxxoRdKIFhLvCFiPxRRI4Od4V6NFWSLROvMaaPaDWAqOrlwPHANuDfIvKRl3/KLrnXiFaVEIUfLBOvMaYPCKlrSlWLcYkOFwKDcSf/rRKR/wpj3Xqcci+NiVgmXmNMHxDKGMh5IrIIeBuIBqar6jm4E/1+FOb69SglBS6RYlRiehfXxBhjwi+UM9EvBf6sqsuCJ6pquYhcHZ5q9UwVRS6dfEyyBRBjTO8XSgD5FbCv7omIxAMDVTVLVd8KW816oMriPADi+1keLGNM7xfKGMizQCDoud+bZhqp8TLxJloAMcb0AaEEkCjvkrQAeI9jwlelnitQ5q6H5Uu1AGKM6f1CCSC5InJ+3RMRmQMcDF+Vei4tz6dE40nxJXZ1VYwxJuxCGQO5AXhCRO7DXaZ2N/CdsNaqh5LKQopJwhdpJ+4bY3q/VgOIqm4DviQiSYCoakn4q9UzRVcXUhph51caY/qGkC4oJSLnApOAOO8qgajqr8NYrx4ptqaIEkukaIzpI0I5kfBB4DLgv3BdWJcCI0NZuYicLSKbRWSriNzWxPwfi8hq77ZORPwikhbKst1RfG0RVVH9uroaxhjTKULprD9ZVb8DFKjqncBJwPDWFhKRSOB+4BxgIjBPRCYGl1HVe1R1iqpOAX4KLFXV/FCW7Y4S/SXUWCJFY0wfEUoAqfTuy0VkCFADjAphuenAVlXd7h36uxCY00L5ecBT7Vy26wUC+CjBbwHEGNNHhBJAXhaRFOAeYBWQxaEf+pYMxR2xVSfbm3YYEUkAzsYlbGzrsteJyAoRWZGbmxtCtcLDX1lEJGqZeI0xfUaLAcS7kNRbqlqoqs/hxj4mqOovQ1i3NDFNmyl7HvCBqua3dVlVna+q01R1Wv/+XXcCX5mXSDEiwfJgGWP6hhYDiKoGgP8Jel6lqkUhrjubhmMlw4C9zZSdS8NWTVuW7RZKCt25ldE+S+VujOkbQunCWiIiF0vd8buhWw6MFZFRIhKDCxIvNS4kIv2A04AX27psd1JR5FogMT5LY2KM6RtCOQ/kh0AiUCsilbjuJVXVFk94UNVaEbkZeB2IBBao6noRucGb/6BX9EJgiaqWtbZsG/etU1XVZ+K1LixjTN8Qypno7T61WlVfBV5tNO3BRs8fBh4OZdnurKbUBZCklAFdXBNjjOkcrQYQETm1qemNLzDV1wXK3fh/cmpGF9fEGGM6RyhdWD8OehyHO0djJfDlsNSoh5LyfIo0geSE+K6uijHGdIpQurDOC34uIsOBP4atRj1URFUhxeKjX0RbjzUwxpieqT15x7OBYzq6Ij1dVFUhpRGWSNEY03eEMgbyvxw6iS8CmAKsCWOdeqS42iKKLBOvMaYPCWUMZEXQ41rgKVX9IEz16bHia4s5EN9kthVjjOmVQgkg/wEqVdUPLsuuiCSoanl4q9azJAWKqY2xVO7GmL4jlDGQt4DgQ4vigTfDU50eKuAnmTICcZbGxBjTd4QSQOJUtbTuifc4IXxV6nmqS70ckJaJ1xjTh4QSQMpE5IS6JyIyFagIX5V6nhIvE29korVAjDF9RyhjILcCz4pIXTbcwbhL3BpPeWEu6UB0kuXBMsb0HaGcSLhcRCYA43GJFDepak3Ya9aDlBe7VO6xyZaJ1xjTd7TahSUiNwGJqrpOVdcCSSLyvfBXreeo9gJIQj/Lg2WM6TtCGQO5VlUL656oagFwbdhq1APVlrlB9MRUa4EYY/qOUAJIRPDFpEQkEogJX5V6nkBZHn4VUiwTrzGmDwllEP114BkReRCX0uQG4LWw1qqnqSigiERSY6O7uibGGNNpQmmB/AR3MuGNwE3A5zQ8sbBH8weUO19ez+J1+9q9jqiqAkrER9uv+muMMT1XqwFEVQPAx8B2YBpwBrAxlJWLyNkisllEtorIbc2UmS0iq0VkvYgsDZqeJSJrvXkrmlq2I0RGCC+u3suyLw62ex3R1UWURVoiRWNM39JsF5aIjAPmAvOAPOBpAFU9PZQVe2Ml9wNn4lLALxeRl1R1Q1CZFODvwNmquktEGl8P9nRVbf8ve4iGp8azO7/9qb3iaooojLKz0I0xfUtLLZBNuNbGeao6S1X/F/C3Yd3Tga2qul1Vq4GFwJxGZb4JPK+quwBU9UAb1t8xAn7+XPrfzMhZ2O5VJASKqYpO6bg6GWNMD9BSALkY2A+8IyIPicgZuBMJQzUU2B30PNubFmwckCoi74rIShH5TtA8BZZ4069rbiMicp2IrBCRFbm5uW2onicikv6BAwyp3Io/oK2Xb4IvUII/NqVdyxpjTE/VbABR1UWqehkwAXgX+AEwUEQeEJGvhrDupoJN41/oKGAqcC5wFvALr+sMYKaqngCcA9wkIqc2U8/5qjpNVaf179++8zAqkkYwjBz2F1e2eVmtrSaRCgJx1oVljOlbQhlEL1PVJ1T168AwYDXQ5IB4I9nA8KDnw4C9TZRZ7G3jILAMmOxtd693fwBYhOsSCwtNHcVIyWFXXtvHQSqL89yDBAsgxpi+pU3XRFfVfFX9h6p+OYTiy4GxIjJKRGJwA/IvNSrzInCKiESJSAIwA9goIoki4gMQkUTgq8C6ttS1LWIHjGGgFLI3N6/Ny5YUumGbqERLpGiM6VtCOZGwXVS1VkRuxp2IGAksUNX1InKDN/9BVd0oIotx55YEgH+q6joRGQ0s8s6riAKeVNXF4aqrb9BYAEr2bcUNy4SuzAsg0UmWyt0Y07eELYAAqOqrwKuNpj3Y6Pk9wD2Npm3H68rqDJEZowGoObitzctWFrlWS1w/y4NljOlb2tSF1WuljgIgsmhnmxetLnGnqSRaADHG9DEWQADiU6mISCKpbHfrZRupy8SblNr4HEhjjOndLIAAiFCSMIwBtfsor65t27Ll+dRoJP1S7CgsY0zfYgHEU9svkxGSw+78Nl7uvbKAIpKIjQ7rcJIxxnQ7FkA8kemjGSa57DpY0qbloioLKY1IClOtjDGm+7IA4kkafBQx4qdg3/Y2LRdTU0RZRL8w1coYY7ovCyCehIFHAVCR07ZDeeNqi6iMtlTuxpi+xwKIR9LcuSAUtK0FkuAvptoy8Rpj+iALIHWSh1BDNHElu9q2mJbgj7MuLGNM32MBpE5EJEVxg0mpykY1tLTuWlNBPFVonKUxMcb0PRZAglQmjWSY5pBbWhVS+ZICd/0RsUy8xpg+yAJIsNRMhssBdoeY1r2s0KUxiUzKCGetjDGmW7IAEiR2wBiSpYKc/Y0vW9K0uky8sT7rwjLG9D0WQIL0G+JSuZfs+yKk8pXFrgUSl2yJFI0xfY8FkCAx/ccAUBtiWveaUpfKPTHFAogxpu+xABIsdSQAUUVZIRX3l7kA4rNMvMaYPiisAUREzhaRzSKyVUSavI66iMwWkdUisl5ElrZl2Q4XHU9hVH+SyrNDKq7lBVRpFMk+OxPdGNP3hC2AiEgkcD9wDjARmCciExuVSQH+DpyvqpOAS0NdNlxKE4YxoHYvVbX+VstGVBZQJD6ioiI7oWbGGNO9hLMFMh3YqqrbVbUaWAjMaVTmm8DzqroLQFUPtGHZsKhL6763sLLVslFVhZSKrxNqZYwx3U84A8hQIPgSf9netGDjgFQReVdEVorId9qwLAAicp2IrBCRFbm5uUdc6aiM0QyUQrIP5LVaNqamiPJI674yxvRN4Qwg0sS0xjlCooCpwLnAWcAvRGRciMu6iarzVXWaqk7r3//Ij4ZKGjwWgMI9W1otG19bRFW05cEyxvRN4Qwg2cDwoOfDgMZn6GUDi1W1TFUPAsuAySEuGxbJg925IJUHWj+UNzFQQnWMBRBjTN8UzgCyHBgrIqNEJAaYC7zUqMyLwCkiEiUiCcAMYGOIy4ZFRPoo96BgR8sFVUnWEgKxlgfLGNM3he1C3qpaKyI3A68DkcACVV0vIjd48x9U1Y0ishj4HAgA/1TVdQBNLRuuujYQn0q5JLaa1r22qoxYalBLpGiM6aPCFkAAVPVV4NVG0x5s9Pwe4J5Qlu0UIhTGDSO1Yk+LxUryD5AKRCRYHixjTN9kZ6I3odI3giGB/RSV1zRbpqTQHfEVlZTeWdUyxphuxQJIU1JHMUxy2XWwpNkilUUugMT4LIAYY/omCyBNiBt4FDHi5+De5o/Eqix254kk9LNEisaYvskCSBNShrpzQUpbSOteU+pSuSdaADHG9FEWQJqQMNAFkNq87c2WCZTnA+BLswBijOmbLIA0JXkINUQRXbSz+TLl+VRoDL4ky4VljOmbLIA0JSKSvOjB+Mp3N1tEKgspEh8iTWVdMcaY3s8CSDPKEoeRUbMPf6DJFFzEVBdSFmGtD2NM32UBpBn+fpkMlxz2FZY3Od9l4rU8WMaYvssCSDOiMsaQLBXs29d0DseE2mKqoi2VuzGm77IA0gyfl9a9qJm07omBEmpiUzqxRsYY071YAGlGyrC6tO5bD59Zn4k3pXMrZYwx3YgFkGZEe2ndpTDrsHmVZUVEix8skaIxpg+zANKc6HjyIjKILz08rXtJgbt0u2XiNcb0ZRZAWlAUP5TUyuzDppd6mXijfRmdXSVjjOk2LIC0oMo3kiG6n/Lq2gbTK7wAEmuZeI0xfZgFkJakjWKgFJKdk99gcnWpy8Qbb4kUjTF9WFgDiIicLSKbRWSriNzWxPzZIlIkIqu92y+D5mWJyFpv+opw1rM58QOOAuBg9uYG02u8AOJLtQBijOm7wnZJWxGJBO4HzgSygeUi8pKqbmhU9D1V/XozqzldVQ+Gq46tSfUO5S3bvxU4pX56oMy1SJJTB3RFtYxpVU1NDdnZ2VRWVnZ1VUw3ERcXx7Bhw4iOju6wdYbzmujTga2quh1ARBYCc4DGAaTbSvZOJvQfbJjWXSoKKNM4EuPju6JaxrQqOzsbn89HZmamJfw0qCp5eXlkZ2czatSoDltvOLuwhgLB6WyzvWmNnSQia0TkNRGZFDRdgSUislJErmtuIyJynYisEJEVubm5HVPzunUnpFFKItHFDdO6R1QVUCyWSNF0X5WVlaSnp1vwMACICOnp6R3eIg1nC6SpT27j1LargJGqWioiXwNeAMZ682aq6l4RGQC8ISKbVHXZYStUnQ/MB5g2bVrTqXPbS4S8mCGHpXWPqS6kLNICiOneLHiYYOH4PISzBZINDA96PgxokJlQVYtVtdR7/CoQLSIZ3vO93v0BYBGuS6zTlSUOZ0DtXlQPxabYmmLLxGuM6fPCGUCWA2NFZJSIxABzgZeCC4jIIPHCoohM9+qTJyKJIq6PSEQSga8C68JY12b5UzIZQi65xYfSuif4i6mOsQBiTHPy8vKYMmUKU6ZMYdCgQQwdOrT+eXV1dYvLrlixgltuuaXVbZx88skdVV0Avv/97zN06FACgUCHrrc3C1sXlqrWisjNwOtAJLBAVdeLyA3e/AeBS4AbRaQWqADmqqqKyEBgkRdbooAnVXVxuOrakuiMMcTs8JOzexsD+h0HQFKghD2WSNGYZqWnp7N69WoA7rjjDpKSkvjRj35UP7+2tpaoqKZ/fqZNm8a0adNa3caHH37YIXUFCAQCLFq0iOHDh7Ns2TJmz57dYesO5vf7iYyMDMu6u0I4x0DquqVebTTtwaDH9wH3NbHcdmByOOsWKt8Qdy5I0d4tcMxxaMDvMvHGpXZxzYwJzZ0vr2fD3uIOXefEIcn86rxJrRcMcuWVV5KWlsZnn33GCSecwGWXXcatt95KRUUF8fHx/Pvf/2b8+PG8++673Hvvvbzyyivccccd7Nq1i+3bt7Nr1y5uvfXW+tZJUlISpaWlvPvuu9xxxx1kZGSwbt06pk6dyuOPP46I8Oqrr/LDH/6QjIwMTjjhBLZv384rr7xyWN3eeecdjjnmGC677DKeeuqp+gCSk5PDDTfcwPbt7kjMBx54gJNPPplHH32Ue++9FxHhuOOO47HHHuPKK6/k61//Opdccslh9bvzzjsZPHgwq1evZsOGDVxwwQXs3r2byspKvv/973Pdde44ocWLF3P77bfj9/vJyMjgjTfeYPz48Xz44Yf079+fQCDAuHHj+Pjjj8nI6PpUSmENIL1B+vCjAag6sA2AspJCkkSReAsgxrTVli1bePPNN4mMjKS4uJhly5YRFRXFm2++ye23385zzz132DKbNm3inXfeoaSkhPHjx3PjjTcedi7DZ599xvr16xkyZAgzZ87kgw8+YNq0aVx//fUsW7aMUaNGMW/evGbr9dRTTzFv3jzmzJnD7bffTk1NDdHR0dxyyy2cdtppLFq0CL/fT2lpKevXr+euu+7igw8+ICMjg/z8/GbXW+fTTz9l3bp19YfQLliwgLS0NCoqKjjxxBO5+OKLCQQCXHvttfX1zc/PJyIigssvv5wnnniCW2+9lTfffJPJkyd3i+ABFkBaFZc2jGqiiCjYAUBxXg5JQESi5cEyPUNbWwrhdOmll9Z34RQVFXHFFVfwxRdfICLU1NQ0ucy5555LbGwssbGxDBgwgJycHIYNG9agzPTp0+unTZkyhaysLJKSkhg9enT9j/a8efOYP3/+Yeuvrq7m1Vdf5c9//jM+n48ZM2awZMkSzj33XN5++20effRRACIjI+nXrx+PPvool1xySf2PeFpa61m5p0+f3uD8i7/97W8sWrQIgN27d/PFF1+Qm5vLqaeeWl+ubr1XX301c+bM4dZbb2XBggVcddVVrW6vs1gAaU1EJLmRg4gvc4fyVhS7E+OjkyyAGNNWiYmJ9Y9/8YtfcPrpp7No0SKysrKaHXeIjY2tfxwZGUltbW1IZYKPnGzJ4sWLKSoq4thjjwWgvLychIQEzj333CbLq2qTh8RGRUXVD8CraoODBYL3+9133+XNN9/ko48+IiEhgdmzZ1NZWdnseocPH87AgQN5++23+eSTT3jiiSdC2q/OYMkUQ1AcN5TUqj0AVBS5a4HEWSJFY45IUVERQ4e6c4sffvjhDl//hAkT2L59O1lZWQA8/fTTTZZ76qmn+Oc//0lWVhZZWVns2LGDJUuWUF5ezhlnnMEDDzwAuAHw4uJizjjjDJ555hny8lxOvLourMzMTFauXAnAiy++2GyLqqioiNTUVBISEti0aRMff/wxACeddBJLly5lx44dDdYL8N3vfpfLL7+cb3zjG91qEN4CSAgqk0cyOLCfqppaqkrcm5qQ3D36II3pqf77v/+bn/70p8ycORO/39/h64+Pj+fvf/87Z599NrNmzWLgwIH069fw8Pvy8nJef/31Bq2NxMREZs2axcsvv8xf//pX3nnnHY499limTp3K+vXrmTRpEj/72c847bTTmDx5Mj/84Q8BuPbaa1m6dCnTp0/nk08+adDqCHb22WdTW1vLcccdxy9+8Qu+9KUvAdC/f3/mz5/PRRddxOTJk7nsssvqlzn//PMpLS3tVt1XABJqM68nmDZtmq5Y0fGJe9c8+zsmr/8DO69ZS84HjzN90x84eONGMgYO6fBtGdMRNm7cyNFHH93V1ehypaWlJCUloarcdNNNjB07lh/84AddXa02W7FiBT/4wQ947733jmg9TX0uRGSlqrZ+3HQTrAUSgviB7lDevN2bCZQXANAvzVogxnR3Dz30EFOmTGHSpEkUFRVx/fXXd3WV2uzuu+/m4osv5ve//31XV+UwNogegtRh4wEo2/8FMRX5FGki/aJjurhWxpjW/OAHP+iRLY5gt912G7fddtjllLoFa4GEIH2oy+8YyNtBVFURpRFJXVwjY4zpetYCCUFEbAK5kk5M8U6iawopi7A8WMYYYwEkRHkxQ/BV7CaGWiqjk7u6OsYY0+WsCytE5YkjGFC7j0R/MVXRKV1dHWOM6XIWQELkT8lkAAWkBgrwx1oXljEtmT17Nq+//nqDaX/5y1/43ve+1+IydYfhf+1rX6OwsPCwMnfccQf33ntvi9t+4YUX2LDh0JWzf/nLX/Lmm2+2ofYts7Tvh1gACVFMxmgAEqQKtUy8xrRo3rx5LFy4sMG0hQsXtpjQMNirr75KSkpKu7bdOID8+te/5itf+Uq71tVY47Tv4RKOEyvDwcZAQuQbMrb+sSS0njzNmG7jtdtg/9qOXeegY+Gcu5udfckll/Dzn/+cqqoqYmNjycrKYu/evcyaNYsbb7yR5cuXU1FRwSWXXMKdd9552PKZmZmsWLGCjIwM7rrrLh599FGGDx9O//79mTp1KuDO8Zg/fz7V1dUcddRRPPbYY6xevZqXXnqJpUuX8tvf/pbnnnuO3/zmN/Vp1t966y1+9KMfUVtby4knnsgDDzxAbGwsmZmZXHHFFbz88svU1NTw7LPPMmHChMPqZWnfG7IWSIj6jzz0YYq0RIrGtCg9PZ3p06ezeLG7DtzChQu57LLLEBHuuusuVqxYweeff87SpUv5/PPPm13PypUrWbhwIZ999hnPP/88y5cvr5930UUXsXz5ctasWcPRRx/Nv/71L04++WTOP/987rnnHlavXs2YMWPqy1dWVnLllVfy9NNPs3btWmpra+vzXAFkZGSwatUqbrzxxma7yerSvl944YW88sor9fmu6tK+r1mzhlWrVjFp0qT6tO9vv/02a9as4a9//Wurr9unn37KXXfdVd+CWrBgAStXrmTFihX87W9/Iy8vj9zcXK699lqee+451qxZw7PPPtsg7TvQaWnfrQUSIl/KAEpIwEc5MRZATE/SQkshnOq6sebMmcPChQtZsGABAM888wzz58+ntraWffv2sWHDBo477rgm1/Hee+9x4YUXkpCQALicUHXWrVvHz3/+cwoLCyktLeWss85qsT6bN29m1KhRjBs3DoArrriC+++/n1tvvRVwAQlg6tSpPP/884ctb2nfDxfWFoiInC0im0Vkq4gcdiqliMwWkSIRWe3dfhnqsp1OhJzIwQDE9bM0Jsa05oILLuCtt95i1apVVFRUcMIJJ7Bjxw7uvfde3nrrLT7//HPOPfdcKisrW1xPUynOwV3h8L777mPt2rX86le/anU9reX9q0sJ31zK+OC075mZmbz//vs89dRTLW6vo9K+r1mzhuOPP75Nad/POeecFve3I4QtgIhIJHA/cA4wEZgnIhObKPqeqk7xbr9u47KdqjjeXbAm0VK5G9OqpKQkZs+ezdVXX10/eF5cXExiYiL9+vUjJyeH1157rcV1nHrqqSxatIiKigpKSkp4+eWX6+eVlJQwePBgampqGlwjw+fzUVJScti6JkyYQFZWFlu3bgXgscce47TTTgt5fyzt++HC2QKZDmxV1e2qWg0sBOZ0wrJhU5U8EgBfqgUQY0Ixb9481qxZw9y5cwGYPHkyxx9/PJMmTeLqq69m5syZLS5fd+30KVOmcPHFF3PKKafUz/vNb37DjBkzOPPMMxsMeM+dO5d77rmH448/nm3bttVPj4uL49///jeXXnopxx57LBEREdxwww0h7YelfW9a2NK5i8glwNmq+l3v+beBGap6c1CZ2cBzQDawF/iRqq4PZdmgdVwHXAcwYsSIqTt37gzL/gDs2rKaPR8s5EtX/A6JsOMPTPdl6dz7ptbSvnd0OvdwDqI31XHZOFqtAkaqaqmIfA14ARgb4rJuoup8YD6464G0u7YhGDFuCiPGTQnnJowxpl3uvvtuHnjggU695G04/0ZnA8ODng/DtTLqqWqxqpZ6j18FokUkI5RljTHGHHLbbbexc+dOZs2a1WnbDGcAWQ6MFZFRIhIDzAVeCi4gIoPEO5xARKZ79ckLZVljTMt609VGzZELx+chbF1YqlorIjcDrwORwAJvfOMGb/6DwCXAjSJSC1QAc9XtZZPLhquuxvQ2cXFx5OXlkZ6e3uxhsKbvUFXy8vKIi4vr0PXaNdGN6YVqamrIzs5u9dwI03fExcUxbNgwoqOjG0zvroPoxpguEh0d3eCMZmPCwY5FNcYY0y4WQIwxxrSLBRBjjDHt0qsG0UUkF2jvqegZwMEOrE5X6237A71vn3rb/kDv26fetj9w+D6NVNV25WfqVQHkSIjIivYeidAd9bb9gd63T71tf6D37VNv2x/o2H2yLixjjDHtYgHEGGNMu1gAOWR+V1egg/W2/YHet0+9bX+g9+1Tb9sf6MB9sjEQY4wx7WItEGOMMe1iAcQYY0y79PkAIiJni8hmEdkqIrd1dX06gohkichaEVktIj0uu6SILBCRAyKyLmhamoi8ISJfePepXVnHtmpmn+4QkT3e+7Tau6hajyAiw0XkHRHZKCLrReT73vQe+z61sE898n0SkTgR+VRE1nj7c6c3vcPeoz49BiIikcAW4EzcRayWA/NUdUOXVuwIiUgWME1Ve+QJUCJyKlAKPKqqx3jT/gjkq+rdXqBPVdWfdGU926KZfboDKFXVe7uybu0hIoOBwaq6SkR8wErgAuBKeuj71MI+fYMe+D5511pK9K74Gg28D3wfuIgOeo/6egtkOrBVVberajWwEJjTxXXq81R1GZDfaPIc4BHv8SO4L3aP0cw+9Viquk9VV3mPS4CNwFB68PvUwj71SOqUek+jvZvSge9RXw8gQ4HdQc+z6cEfmCAKLBGRlSJyXVdXpoMMVNV94L7owIAurk9HuVlEPve6uHpMd08wEckEjgc+oZe8T432CXro+yQikSKyGjgAvKGqHfoe9fUA0tSl2npDn95MVT0BOAe4yes+Md3PA8AYYAqwD/ifLq1NO4hIEvAccKuqFnd1fTpCE/vUY98nVfWr6hRgGDBdRI7pyPX39QCSDQwPej4M2NtFdekwqrrXuz8ALMJ11fV0OV4fdV1f9YEurs8RU9Uc7wseAB6ih71PXr/6c8ATqvq8N7lHv09N7VNPf58AVLUQeBc4mw58j/p6AFkOjBWRUSISA8wFXuriOh0REUn0BgARkUTgq8C6lpfqEV4CrvAeXwG82IV16RB1X2LPhfSg98kboP0XsFFV/xQ0q8e+T83tU099n0Skv4ikeI/jga8Am+jA96hPH4UF4B2S9xcgEligqnd1bY2OjIiMxrU6wF2y+Mmetk8i8hQwG5d2Ogf4FfAC8AwwAtgFXKqqPWZQupl9mo3rFlEgC7i+rm+6uxORWcB7wFog4E2+HTdm0CPfpxb2aR498H0SkeNwg+SRuMbCM6r6axFJp4Peoz4fQIwxxrRPX+/CMsYY004WQIwxxrSLBRBjjDHtYgHEGGNMu1gAMcYY0y4WQIxpAxHxB2VlXd2RGZxFJDM4W68x3V1UV1fAmB6mwksNYUyfZy0QYzqAdw2WP3jXX/hURI7ypo8Ukbe8RHxvicgIb/pAEVnkXathjYic7K0qUkQe8q7fsMQ7g9iYbskCiDFtE9+oC+uyoHnFqjoduA+X3QDv8aOqehzwBPA3b/rfgKWqOhk4AVjvTR8L3K+qk4BC4OKw7o0xR8DORDemDUSkVFWTmpieBXxZVbd7Cfn2q2q6iBzEXaSoxpu+T1UzRCQXGKaqVUHryMSl3B7rPf8JEK2qv+2EXTOmzawFYkzH0WYeN1emKVVBj/3YOKXpxiyAGNNxLgu6/8h7/CEuyzPAt3CXFQV4C7gR6i/6k9xZlTSmo9i/G2PaJt67wludxapadyhvrIh8gvtjNs+bdguwQER+DOQCV3nTvw/MF5FrcC2NG3EXKzKmx7AxEGM6gDcGMk1VD3Z1XYzpLNaFZYwxpl2sBWKMMaZdrAVijDGmXSyAGGOMaRcLIMYYY9rFAogxxph2sQBijDGmXf4/25estL1hlrYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define the densely connected layer\n",
    "#import Optimizers\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2048*5*5, 256) #256 comme les chercheurs\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' #pour activer la parallélisation\n",
    "model = DenseNet().to(device)\n",
    "criterion = nn.BCELoss() #Binary cross Entropy\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=2e-5) #RMSprop\n",
    "\n",
    "train_labels = train_labels.reshape(-1, 1).float()\n",
    "validation_labels = validation_labels.reshape(-1, 1).float()\n",
    "\n",
    "# Initialize lists to store training and validation loss and accuracy\n",
    "train_loss_values = []\n",
    "train_accuracy_values = []\n",
    "validation_loss_values = []\n",
    "validation_accuracy_values = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(30):\n",
    "    # Forward pass\n",
    "    outputs = model(train_features)\n",
    "    loss = criterion(outputs, train_labels)\n",
    "    train_loss_values.append(loss.item())\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Calculate the accuracy on the training set\n",
    "    with torch.no_grad():\n",
    "        train_outputs = model(train_features)\n",
    "        train_predicted = (train_outputs > 0.5).float()\n",
    "        train_accuracy = (train_predicted == train_labels).float().mean()\n",
    "        train_accuracy_values.append(train_accuracy.item())\n",
    "    \n",
    "    # Calculate the accuracy on the validation set\n",
    "    with torch.no_grad():\n",
    "        validation_outputs = model(validation_features)\n",
    "        validation_predicted = (validation_outputs > 0.5).float()\n",
    "        validation_loss = criterion(validation_outputs, validation_labels)\n",
    "        validation_loss_values.append(validation_loss.item())\n",
    "        validation_accuracy = (validation_predicted == validation_labels).float().mean()\n",
    "        validation_accuracy_values.append(validation_accuracy.item())\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 30, loss.item()))\n",
    "\n",
    "#Plot the loss values\n",
    "plt.figure()\n",
    "sns.lineplot(x=range(30), y=train_loss_values, label='Training Loss')\n",
    "sns.lineplot(x=range(30), y=validation_loss_values, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss with pre-trained features')\n",
    "plt.legend()\n",
    "\n",
    "#Plot the accuracy values\n",
    "plt.figure()\n",
    "sns.lineplot(x=range(30), y=train_accuracy_values, label='Training Accuracy')\n",
    "sns.lineplot(x=range(30), y=validation_accuracy_values, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy with pre-trained features')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Le modèle avec RESNET 50 a une accuracy légèrement plus faible pour l'accuracy et légèrement plus élevée pour la loss\n",
    "#(89% vs 92% pour l'accuracy et 0.25 vs 0.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14c2befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model with pretrained features in Numpy array (no data augmentation)\n",
    "torch.save(model.state_dict(), 'tomnod_transfer_RESNET.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b62c38b2",
   "metadata": {},
   "source": [
    "# ALEXNET"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6185990a",
   "metadata": {},
   "source": [
    "## Utilisation d'un Random Forest sur les features extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca0e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1698a089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pierre/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/pierre/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "conv_base_all = torchvision.models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ba45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((150, 150)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70406388",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root='./train_another', transform=data_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "validation_dataset = torchvision.datasets.ImageFolder(root='./validation_another', transform=data_transform)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(root='./test', transform=data_transform)\n",
    "test_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "test_dataset_unbalanced = torchvision.datasets.ImageFolder(root='./test_another', transform=data_transform)\n",
    "test_loader_unbalanced = torch.utils.data.DataLoader(validation_dataset, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07fe183a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images  belonging to 2 classes.\n",
      "Found 21000 images  belonging to 4 classes.\n",
      "Found 21000 images  belonging to 2 classes.\n",
      "Found 9000 images  belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_classes = len(os.listdir('./train_another'))\n",
    "validation_classes = len(os.listdir('./validation_another'))\n",
    "test_classes = len(os.listdir('./test'))\n",
    "test_classes_unbalanced = len(os.listdir('./test_another'))\n",
    "\n",
    "print(\"Found {} images  belonging to {} classes.\".format(len(train_dataset), train_classes))\n",
    "print(\"Found {} images  belonging to {} classes.\".format(len(validation_dataset), validation_classes))\n",
    "print(\"Found {} images  belonging to {} classes.\".format(len(validation_dataset), test_classes))\n",
    "print(\"Found {} images  belonging to {} classes.\".format(len(test_dataset_unbalanced), test_classes_unbalanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34114a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try transfer learning type A \n",
    "#using feature extraction from AlexNet\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "conv_base = models.alexnet(weights='AlexNet_Weights.IMAGENET1K_V1')\n",
    "\n",
    "layers = list(conv_base.children())[:-2] #we only keep the features part\n",
    "\n",
    "#we should put [:-1] if we want to add this layer (avgpool): AdaptiveAvgPool2d(output_size=(6, 6)\n",
    "\n",
    "conv_base = nn.Sequential(*layers) \n",
    "\n",
    "#conv_base.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc1d83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze model weights\n",
    "for param in conv_base.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbbc85af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def extract_features(directory, sample_count, conv_base, batch_size, datagen):\n",
    "    features = torch.zeros(size=(sample_count, 256 * 3 * 3))\n",
    "    labels = torch.zeros(size=(sample_count,))\n",
    "    \n",
    "    dataloader = DataLoader(datagen, batch_size=batch_size, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs_batch, labels_batch) in enumerate(dataloader):\n",
    "            features_batch = conv_base(inputs_batch)\n",
    "            features[i * batch_size: (i + 1) * batch_size] = features_batch.view(batch_size, -1)\n",
    "            labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
    "            if (i + 1) * batch_size >= sample_count: # Stop when all samples have been extracted\n",
    "                break\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "684e4363",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir='./train_another'\n",
    "validation_dir='./validation_another'\n",
    "test_dir='./test'\n",
    "testunbalanced_dir='./test_another' #9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bacf4441",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_train = torchvision.datasets.ImageFolder(root=train_dir, transform=data_transform)\n",
    "train_features, train_labels = extract_features(train_dir, 10000, conv_base,20,datagen_train)\n",
    "datagen_val=torchvision.datasets.ImageFolder(root=validation_dir, transform=data_transform)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 2000, conv_base,20,datagen_val)\n",
    "datagen_test=torchvision.datasets.ImageFolder(root=test_dir, transform=data_transform)\n",
    "test_features, test_labels = extract_features(test_dir, 2000, conv_base,20,datagen_test)\n",
    "datagen_unbalanced = torchvision.datasets.ImageFolder(testunbalanced_dir, transform=data_transform)\n",
    "testunbalanced_features, testunbalanced_labels = extract_features(testunbalanced_dir, 9000,conv_base,20, datagen_unbalanced)\n",
    "testunbalanced_features = np.reshape(testunbalanced_features, (9000, 3*3*256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "326668f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "RF = RandomForestClassifier(max_depth=10, random_state=42)\n",
    "RF.fit(train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "659ff7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc =  0.882\n"
     ]
    }
   ],
   "source": [
    "#balanced validation set \n",
    "score4 = RF.score(validation_features, validation_labels)\n",
    "print(\"Validation acc = \", score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e1d3037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc =  0.9255\n"
     ]
    }
   ],
   "source": [
    "#test set \n",
    "score5 = RF.score(test_features, test_labels)\n",
    "print(\"Test acc = \", score5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5359f05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test unbalanced acc =  0.8672222222222222\n"
     ]
    }
   ],
   "source": [
    "#test unbalanced set \n",
    "score6 = RF.score(testunbalanced_features, testunbalanced_labels)\n",
    "print(\"Test unbalanced acc = \", score6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13cf22ca",
   "metadata": {},
   "source": [
    "## Avec un SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2feed85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d426c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = svm.SVC()\n",
    "svm.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06a57730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation acc =  0.9415\n"
     ]
    }
   ],
   "source": [
    "#balanced validation set \n",
    "svm_score_val = svm.score(validation_features, validation_labels)\n",
    "print(\"Validation acc = \", svm_score_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8bf5765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc =  0.955\n"
     ]
    }
   ],
   "source": [
    "#test set \n",
    "svm_score_test = svm.score(test_features, test_labels)\n",
    "print(\"Test acc = \", svm_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a521a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test unbalanced acc =  0.9331111111111111\n"
     ]
    }
   ],
   "source": [
    "#test unbalanced set \n",
    "svm_score_unba = svm.score(testunbalanced_features, testunbalanced_labels)\n",
    "print(\"Test unbalanced acc = \", svm_score_unba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "296c08b3",
   "metadata": {},
   "source": [
    "# Transfer learning de type B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91a53bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pierre/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/pierre/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 150, 150]           1,792\n",
      "              ReLU-2         [-1, 64, 150, 150]               0\n",
      "            Conv2d-3         [-1, 64, 150, 150]          36,928\n",
      "              ReLU-4         [-1, 64, 150, 150]               0\n",
      "         MaxPool2d-5           [-1, 64, 75, 75]               0\n",
      "            Conv2d-6          [-1, 128, 75, 75]          73,856\n",
      "              ReLU-7          [-1, 128, 75, 75]               0\n",
      "            Conv2d-8          [-1, 128, 75, 75]         147,584\n",
      "              ReLU-9          [-1, 128, 75, 75]               0\n",
      "        MaxPool2d-10          [-1, 128, 37, 37]               0\n",
      "           Conv2d-11          [-1, 256, 37, 37]         295,168\n",
      "             ReLU-12          [-1, 256, 37, 37]               0\n",
      "           Conv2d-13          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-14          [-1, 256, 37, 37]               0\n",
      "           Conv2d-15          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-16          [-1, 256, 37, 37]               0\n",
      "        MaxPool2d-17          [-1, 256, 18, 18]               0\n",
      "           Conv2d-18          [-1, 512, 18, 18]       1,180,160\n",
      "             ReLU-19          [-1, 512, 18, 18]               0\n",
      "           Conv2d-20          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-21          [-1, 512, 18, 18]               0\n",
      "           Conv2d-22          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-23          [-1, 512, 18, 18]               0\n",
      "        MaxPool2d-24            [-1, 512, 9, 9]               0\n",
      "           Conv2d-25            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-26            [-1, 512, 9, 9]               0\n",
      "           Conv2d-27            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-28            [-1, 512, 9, 9]               0\n",
      "           Conv2d-29            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-30            [-1, 512, 9, 9]               0\n",
      "        MaxPool2d-31            [-1, 512, 4, 4]               0\n",
      "================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 96.55\n",
      "Params size (MB): 56.13\n",
      "Estimated Total Size (MB): 152.94\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch.cuda\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "conv_base = models.vgg16(pretrained=True) # pre-trained model\n",
    "conv_base = conv_base.to(device)\n",
    "conv_base = torch.nn.Sequential(*list(conv_base.children())[:-2]) # remove the last layer\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(conv_base, (3, 150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1431b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data augmentation with the same parameters used by the scientists\n",
    "#freeze the paramters of the pre-trained network\n",
    "\n",
    "for param in conv_base.parameters():\n",
    "    param.requires_grad = False # les gradients ne seront pas calculés lors de la phse d'entaînement pour ces paramtères\n",
    "\n",
    "\n",
    "# Add custom fully connected layers\n",
    "class CustomClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_base = conv_base\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(4*4*512, 512) #25088, poids de la dernière couche\n",
    "        self.fc2 = nn.Linear(512, 20)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc3 = nn.Linear(20,1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_base(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = CustomClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b90ae542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 150, 150])\n",
      "torch.Size([2, 512, 4, 4])\n",
      "torch.Size([2, 8192])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2, 512])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([2, 1])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 150, 150]           1,792\n",
      "              ReLU-2         [-1, 64, 150, 150]               0\n",
      "            Conv2d-3         [-1, 64, 150, 150]          36,928\n",
      "              ReLU-4         [-1, 64, 150, 150]               0\n",
      "         MaxPool2d-5           [-1, 64, 75, 75]               0\n",
      "            Conv2d-6          [-1, 128, 75, 75]          73,856\n",
      "              ReLU-7          [-1, 128, 75, 75]               0\n",
      "            Conv2d-8          [-1, 128, 75, 75]         147,584\n",
      "              ReLU-9          [-1, 128, 75, 75]               0\n",
      "        MaxPool2d-10          [-1, 128, 37, 37]               0\n",
      "           Conv2d-11          [-1, 256, 37, 37]         295,168\n",
      "             ReLU-12          [-1, 256, 37, 37]               0\n",
      "           Conv2d-13          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-14          [-1, 256, 37, 37]               0\n",
      "           Conv2d-15          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-16          [-1, 256, 37, 37]               0\n",
      "        MaxPool2d-17          [-1, 256, 18, 18]               0\n",
      "           Conv2d-18          [-1, 512, 18, 18]       1,180,160\n",
      "             ReLU-19          [-1, 512, 18, 18]               0\n",
      "           Conv2d-20          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-21          [-1, 512, 18, 18]               0\n",
      "           Conv2d-22          [-1, 512, 18, 18]       2,359,808\n",
      "             ReLU-23          [-1, 512, 18, 18]               0\n",
      "        MaxPool2d-24            [-1, 512, 9, 9]               0\n",
      "           Conv2d-25            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-26            [-1, 512, 9, 9]               0\n",
      "           Conv2d-27            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-28            [-1, 512, 9, 9]               0\n",
      "           Conv2d-29            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-30            [-1, 512, 9, 9]               0\n",
      "        MaxPool2d-31            [-1, 512, 4, 4]               0\n",
      "          Flatten-32                 [-1, 8192]               0\n",
      "           Linear-33                  [-1, 512]       4,194,816\n",
      "             ReLU-34                  [-1, 512]               0\n",
      "           Linear-35                   [-1, 20]          10,260\n",
      "          Dropout-36                   [-1, 20]               0\n",
      "           Linear-37                    [-1, 1]              21\n",
      "          Sigmoid-38                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 18,919,785\n",
      "Trainable params: 4,205,097\n",
      "Non-trainable params: 14,714,688\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 96.62\n",
      "Params size (MB): 72.17\n",
      "Estimated Total Size (MB): 169.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fbcfc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import seaborn as sns\n",
    "\n",
    "#data augmentation   \n",
    "train_datagen = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(40),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(1, 1), shear=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "val_datagen = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) \n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='./train_another', transform=train_datagen)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "validation_dataset = torchvision.datasets.ImageFolder(root='./validation_another', transform=val_datagen)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=20, shuffle=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e513fa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [12:11<00:00,  1.46s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m val_inputs, val_labels \u001b[39m=\u001b[39m val_data\n\u001b[1;32m     39\u001b[0m val_inputs, val_labels \u001b[39m=\u001b[39m val_inputs\u001b[39m.\u001b[39mto(device), val_labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 40\u001b[0m val_outputs \u001b[39m=\u001b[39m model(val_inputs)\n\u001b[1;32m     41\u001b[0m val_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m criterion(val_outputs, val_labels\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     42\u001b[0m accuracy_val \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39mround(val_outputs) \u001b[39m==\u001b[39m val_labels\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem() \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(val_labels)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [20], line 22\u001b[0m, in \u001b[0;36mCustomClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 22\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_base(x)\n\u001b[1;32m     23\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten(x)\n\u001b[1;32m     24\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1212\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1209\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   1210\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[0;32m-> 1212\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1213\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1214\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the loss function and the optimizer, with the same parameters as the scientists implemented\n",
    "\n",
    "history = {'loss': [], 'val_loss': [], 'acc': [], 'val_acc': []}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCELoss() #Binary cross-entrpoy\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=2e-5) \n",
    "\n",
    "for epoch in range(30):\n",
    "    running_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    for i, data in enumerate(tqdm(train_dataloader), 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.float().view(-1,1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        accuracy += (torch.round(outputs) == labels.float().view(-1,1)).sum().item() / len(labels)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        accuracy_val = 0\n",
    "\n",
    "        start = time.perf_counter()\n",
    "        for val_data in validation_dataloader:\n",
    "            val_inputs, val_labels = val_data\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "            val_outputs = model(val_inputs)\n",
    "            val_loss += criterion(val_outputs, val_labels.float().view(-1,1)).item()\n",
    "            accuracy_val += (torch.round(val_outputs) == val_labels.float().view(-1,1)).sum().item() / len(val_labels)\n",
    "        val_loss /= len(validation_loader)\n",
    "        accuracy_val /= len(validation_loader)\n",
    "        history['loss'].append(running_loss / 100)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['acc'].append(accuracy / 100)\n",
    "        history['val_acc'].append(accuracy_val)\n",
    "        running_loss = 0.0\n",
    "        accuracy = 0.0\n",
    "        if i % 20 == 0: # Only print every 20 iterations\n",
    "            print('Epoch {}/30, 500/500 [==============================] - loss: {:.4f} - acc: {:.4f} - val_loss: {:.4f} - val_acc: {:.4f}'.format(\n",
    "                epoch + 1, history['loss'][-1], history['acc'][-1], history['val_loss'][-1], history['val_acc'][-1]))\n",
    "end = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643149ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot the loss and accuracy\n",
    "\n",
    "\n",
    "plt.plot(epoch, history['acc'], 'bo', label='Training acc')\n",
    "plt.plot(epoch, history['val_acc'], 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy with data aug and dropout (Adam)')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "epoch = range(1, len(history['loss']) + 1)\n",
    "plt.plot(epoch, history['loss'], 'bo', label='Training loss')\n",
    "plt.plot(epoch, history['val_loss'], 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss with data aug and dropout (Adam)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
